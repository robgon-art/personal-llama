{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robgon-art/personal-llama/blob/main/2_Generate_Q%26A_ChatGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai llama_index\n",
        "!gdown 15vLnOyyJBtkjhizR-FqMiILpSD-tYgT3\n",
        "!unzip robgon_articles_md.zip"
      ],
      "metadata": {
        "id": "qx81W006yuu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'YOUR_OPENAI_API_KEY'"
      ],
      "metadata": {
        "id": "etBI6190AVGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "A68XLJdgZVKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from llama_index import (\n",
        "    SimpleDirectoryReader,\n",
        "    VectorStoreIndex,\n",
        "    ServiceContext,\n",
        ")\n",
        "from llama_index.llms import LlamaCPP\n",
        "from llama_index.llms.llama_utils import messages_to_prompt, completion_to_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "N2QeQ80TZalS",
        "outputId": "8c20599a-a75d-445e-9d8a-c8bdcb280742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "def extract_info_from_file(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = [line.strip() for line in f.readlines()[:6]]\n",
        "\n",
        "    info = {\n",
        "        'filename': filename,\n",
        "        'title': lines[0].replace('# ', ''),\n",
        "        'subtitle': lines[1].replace('## ', ''),\n",
        "        'author': lines[2],\n",
        "        'date': lines[4].replace('</br>', ''),\n",
        "        'nickname': lines[4].split(' - ')[0],\n",
        "        'url': lines[4].split(' - ')[1].replace('</br></br>', '')\n",
        "    }\n",
        "    return info\n",
        "\n",
        "files = glob.glob('/content/robgon_articles_md/*.md')\n",
        "data_list = [extract_info_from_file(file) for file in files]\n",
        "\n",
        "df = pd.DataFrame(data_list)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1CH3w4MuZfFa",
        "outputId": "525d1f9e-801e-437f-a615-e8f5ce185a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             filename  \\\n",
              "0   /content/robgon_articles_md/2023-03-07_using-o...   \n",
              "1   /content/robgon_articles_md/2021-12-01_sex-and...   \n",
              "2   /content/robgon_articles_md/2021-06-03_ai-meme...   \n",
              "3   /content/robgon_articles_md/2021-03-01_using-o...   \n",
              "4   /content/robgon_articles_md/2022-06-09_clip-an...   \n",
              "5   /content/robgon_articles_md/2021-09-01_ai-tune...   \n",
              "6   /content/robgon_articles_md/2022-09-06_using-a...   \n",
              "7   /content/robgon_articles_md/2021-07-05_magnet-...   \n",
              "8   /content/robgon_articles_md/2021-04-01_ganscap...   \n",
              "9   /content/robgon_articles_md/2023-01-17_using-c...   \n",
              "10  /content/robgon_articles_md/2020-08-03_machine...   \n",
              "11  /content/robgon_articles_md/2023-04-18_writing...   \n",
              "12  /content/robgon_articles_md/2022-07-07_e-dall-...   \n",
              "13  /content/robgon_articles_md/2020-12-01_frost-s...   \n",
              "14  /content/robgon_articles_md/2022-02-05_portrai...   \n",
              "15  /content/robgon_articles_md/2022-05-09_greenli...   \n",
              "16  /content/robgon_articles_md/2021-01-01_creatin...   \n",
              "17  /content/robgon_articles_md/2022-01-10_ganfolk...   \n",
              "18  /content/robgon_articles_md/2022-03-08_deep-ha...   \n",
              "19  /content/robgon_articles_md/2022-08-08_explori...   \n",
              "20  /content/robgon_articles_md/2020-11-01_buildin...   \n",
              "21  /content/robgon_articles_md/2022-10-04_i-once-...   \n",
              "22  /content/robgon_articles_md/2021-05-02_voxmorp...   \n",
              "23  /content/robgon_articles_md/2022-04-06_big-art...   \n",
              "24  /content/robgon_articles_md/2021-02-01_invento...   \n",
              "25  /content/robgon_articles_md/2021-10-27_spookyg...   \n",
              "26  /content/robgon_articles_md/2022-12-01_explori...   \n",
              "27  /content/robgon_articles_md/2022-11-09_digital...   \n",
              "28  /content/robgon_articles_md/2023-05-10_writing...   \n",
              "29  /content/robgon_articles_md/2023-01-04_using-c...   \n",
              "30  /content/robgon_articles_md/2023-07-25_muybrid...   \n",
              "31  /content/robgon_articles_md/2020-09-01_got-wri...   \n",
              "32  /content/robgon_articles_md/2023-02-07_using-c...   \n",
              "33  /content/robgon_articles_md/2020-10-02_benford...   \n",
              "34  /content/robgon_articles_md/2021-10-06_ganshar...   \n",
              "35  /content/robgon_articles_md/2023-06-14_writing...   \n",
              "\n",
              "                                                title  \\\n",
              "0   Using OpenCLIP for Image Search and Automatic ...   \n",
              "1            Sex and Drugs and Organic Topic Modeling   \n",
              "2   AI-Memer: Using Machine Learning to Create Fun...   \n",
              "3    Using OpenAI’s CLIP to Search for Design Patents   \n",
              "4   CLIP and PASTE: Using AI to Create Photo Colla...   \n",
              "5                                 #Hands-on Tutorials   \n",
              "6   Using AI to Create New Comic Strips without Wr...   \n",
              "7                                 #Hands-on Tutorials   \n",
              "8                                 #Hands-on Tutorials   \n",
              "9   Using ChatGPT as a Creative Writing Partner — ...   \n",
              "10        MachineRay: Using AI to Create Abstract Art   \n",
              "11           Writing Songs with GPT-4: Part 1, Lyrics   \n",
              "12  E-DALL-E: Creating Digital Art with Varying As...   \n",
              "13  Frost Songs: Using AI to Generate Music from P...   \n",
              "14                      Portraits from the Multiverse   \n",
              "15  GreenLIT: Using GPT-J with Multi-Task Learning...   \n",
              "16           Creating Abstract Art with StyleGAN2 ADA   \n",
              "17  GANfolk: Using AI to Create Portraits of Ficti...   \n",
              "18  Deep Haiku: Teaching GPT-J to Compose with Syl...   \n",
              "19          Exploring DALL-E for Digital Art Creation   \n",
              "20                 Building an AI 8-Ball with RoBERTa   \n",
              "21  I Once Trained an AI to Rhyme, and It Took GPT...   \n",
              "22  VoxMorphia: Using AI for Style Transfer of Son...   \n",
              "23  BIG.art: Using Machine Learning to Create High...   \n",
              "24  InventorBot: Using AI to Generate New Ideas in...   \n",
              "25  SpookyGAN - Rendering Scary Faces with Machine...   \n",
              "26   Exploring Midjourney V4 for Creating Digital Art   \n",
              "27  Digital Art Showdown: Stable Diffusion, DALL-E...   \n",
              "28           Writing Songs with GPT-4: Part 2, Chords   \n",
              "29  Using ChatGPT as a Creative Writing Partner — ...   \n",
              "30  Muybridge Derby: Bringing Animal Locomotion Ph...   \n",
              "31      Got Writer’s Block? It’s GPT-2 to the Rescue!   \n",
              "32  Using ChatGPT as a Creative Writing Partner — ...   \n",
              "33               Benford’s Law — A Simple Explanation   \n",
              "34  GANshare: Creating and Curating Art with AI fo...   \n",
              "35         Writing Songs with GPT-4: Part 3, Melodies   \n",
              "\n",
              "                                             subtitle  \\\n",
              "0   How LAION used more data and new ML training t...   \n",
              "1   Using GPT-J to analyze the lyrics of Rock & Ro...   \n",
              "2   How to create new memes using images from Wiki...   \n",
              "3   Using natural language to search and find over...   \n",
              "4   How to use ML models to extract objects from p...   \n",
              "5   # AI-Tunes: Creating New Songs with Artificial...   \n",
              "6   A tutorial on how to use GPT-3 and DALL-E to g...   \n",
              "7   # MAGNet: Modern Art Generator using Deep Neur...   \n",
              "8   # GANscapes: Using AI to Create New Impression...   \n",
              "9   How the latest language model from OpenAI can ...   \n",
              "10  How I trained a GAN using public domain paintings   \n",
              "11  How to use the latest language model from Open...   \n",
              "12  How to expand images generated with DALL-E Min...   \n",
              "13  How Robert Frost’s words can breathe life into...   \n",
              "14  Using Machine Learning to change the gender, e...   \n",
              "15  How to fine-tune an ML model to create TV show...   \n",
              "16  How I used Adaptive Discriminator Augmentation...   \n",
              "17  How to use StyleGAN2, VQGAN, and GPT-3 to synt...   \n",
              "18  How to generate rhythmic prose after fine-tuni...   \n",
              "19  I tested OpenAI’s text-to-image generator to s...   \n",
              "20  Can an Artificial Neural Network answer yes/no...   \n",
              "21  Since the Colab was slow, I upgraded to Pro. E...   \n",
              "22  How I used GPT-3 to reimagine classic songs in...   \n",
              "23  How to use GLIDE and BSRGAN to create ultra-hi...   \n",
              "24  How a neural network trained on the US Patent ...   \n",
              "25  How to use StyleGAN 2, VQGAN, and CLIP to crea...   \n",
              "26  A deep dive into the features and options for ...   \n",
              "27  A comparison of popular AI diffusion models fo...   \n",
              "28  How to use the latest large language model fro...   \n",
              "29  How the latest language model from OpenAI can ...   \n",
              "30  How I used Midjourney and RunwayML to transfor...   \n",
              "31  Using AI to create plot summaries of books tha...   \n",
              "32  How the latest language model from OpenAI can ...   \n",
              "33  What Latif Nasser didn’t tell us about the “Fi...   \n",
              "34  Using the CLIP and VQGAN models to generate Ch...   \n",
              "35  How to use the latest language model from Open...   \n",
              "\n",
              "                                               author  \\\n",
              "0                                 Robert A. Gonsalves   \n",
              "1                                 Robert A. Gonsalves   \n",
              "2                                 Robert A. Gonsalves   \n",
              "3                                 Robert A. Gonsalves   \n",
              "4                                 Robert A. Gonsalves   \n",
              "5   ## How I fine-tuned OpenAI’s GPT-3 to generate...   \n",
              "6                                 Robert A. Gonsalves   \n",
              "7   ## How I used CLIP, SWAGAN, and a custom genet...   \n",
              "8   ## How I trained StyleGAN2 ADA with 5,000 Impr...   \n",
              "9                                 Robert A. Gonsalves   \n",
              "10                                Robert A. Gonsalves   \n",
              "11                                Robert A. Gonsalves   \n",
              "12                                Robert A. Gonsalves   \n",
              "13                                Robert A. Gonsalves   \n",
              "14                                Robert A. Gonsalves   \n",
              "15                                Robert A. Gonsalves   \n",
              "16                                Robert A. Gonsalves   \n",
              "17                                Robert A. Gonsalves   \n",
              "18                                Robert A. Gonsalves   \n",
              "19                                Robert A. Gonsalves   \n",
              "20                                Robert A. Gonsalves   \n",
              "21                                Robert A. Gonsalves   \n",
              "22                                Robert A. Gonsalves   \n",
              "23                                Robert A. Gonsalves   \n",
              "24                                Robert A. Gonsalves   \n",
              "25                                Robert A. Gonsalves   \n",
              "26                                Robert A. Gonsalves   \n",
              "27                                Robert A. Gonsalves   \n",
              "28                                Robert A. Gonsalves   \n",
              "29                                Robert A. Gonsalves   \n",
              "30                                Robert A. Gonsalves   \n",
              "31                                Robert A. Gonsalves   \n",
              "32                                Robert A. Gonsalves   \n",
              "33                                Robert A. Gonsalves   \n",
              "34                                Robert A. Gonsalves   \n",
              "35                                Robert A. Gonsalves   \n",
              "\n",
              "                                                 date  \\\n",
              "0   OpenClip - https://medium.com/towards-data-sci...   \n",
              "1   Organic Topic Modelling - https://medium.com/t...   \n",
              "2   AIMemer - https://medium.com/towards-data-scie...   \n",
              "3   CLIP Patents - https://medium.com/towards-data...   \n",
              "4   Clip-n-Paste - https://medium.com/towards-data...   \n",
              "5   AITunes - https://medium.com/towards-data-scie...   \n",
              "6   AI Comics - https://medium.com/towards-data-sc...   \n",
              "7   MAGnet - https://medium.com/towards-data-scien...   \n",
              "8   Ganscapes - https://medium.com/towards-data-sc...   \n",
              "9   ChatGPT Tunes - https://medium.com/towards-dat...   \n",
              "10  MachineRay - https://medium.com/towards-data-s...   \n",
              "11  GPT-4 Lyrics - https://medium.com/towards-data...   \n",
              "12  E-DALL-E - https://medium.com/towards-data-sci...   \n",
              "13  Frost Melodies - https://medium.com/towards-da...   \n",
              "14  Multiverse Portraits - https://medium.com/geek...   \n",
              "15  GreenLit - https://medium.com/towards-data-sci...   \n",
              "16  StyleGAN Abstract Art - https://medium.com/tow...   \n",
              "17  GANfolk - https://medium.com/towards-data-scie...   \n",
              "18  Deep Haiku - https://medium.com/towards-data-s...   \n",
              "19  DALL-E Art - https://medium.com/towards-data-s...   \n",
              "20  AI 8-Ball - https://medium.com/towards-data-sc...   \n",
              "21  AI Limericks - https://medium.com/towards-data...   \n",
              "22  Voxmorphia - https://medium.com/towards-data-s...   \n",
              "23  BigArt - https://medium.com/towards-data-scien...   \n",
              "24  InventorBot - https://medium.com/geekculture/i...   \n",
              "25  SpookyGAN - https://medium.com/towards-data-sc...   \n",
              "26  Midjourney Art - https://medium.com/towards-da...   \n",
              "27  Digital Art Showdown - https://medium.com/towa...   \n",
              "28  GPT-4 Chords - https://medium.com/towards-data...   \n",
              "29  ChatGPT Prose - https://medium.com/towards-dat...   \n",
              "30  Muybridge Derby - https://medium.com/towards-d...   \n",
              "31  PlotJam - https://medium.com/towards-data-scie...   \n",
              "32  ChatGPT Pictures - https://medium.com/towards-...   \n",
              "33  Benford’s Law, Simple Explanation - https://me...   \n",
              "34  GANshare - https://medium.com/towards-data-sci...   \n",
              "35  GPT-4 Melodies - https://medium.com/towards-da...   \n",
              "\n",
              "                             nickname  \\\n",
              "0                            OpenClip   \n",
              "1             Organic Topic Modelling   \n",
              "2                             AIMemer   \n",
              "3                        CLIP Patents   \n",
              "4                        Clip-n-Paste   \n",
              "5                             AITunes   \n",
              "6                           AI Comics   \n",
              "7                              MAGnet   \n",
              "8                           Ganscapes   \n",
              "9                       ChatGPT Tunes   \n",
              "10                         MachineRay   \n",
              "11                       GPT-4 Lyrics   \n",
              "12                           E-DALL-E   \n",
              "13                     Frost Melodies   \n",
              "14               Multiverse Portraits   \n",
              "15                           GreenLit   \n",
              "16              StyleGAN Abstract Art   \n",
              "17                            GANfolk   \n",
              "18                         Deep Haiku   \n",
              "19                         DALL-E Art   \n",
              "20                          AI 8-Ball   \n",
              "21                       AI Limericks   \n",
              "22                         Voxmorphia   \n",
              "23                             BigArt   \n",
              "24                        InventorBot   \n",
              "25                          SpookyGAN   \n",
              "26                     Midjourney Art   \n",
              "27               Digital Art Showdown   \n",
              "28                       GPT-4 Chords   \n",
              "29                      ChatGPT Prose   \n",
              "30                    Muybridge Derby   \n",
              "31                            PlotJam   \n",
              "32                   ChatGPT Pictures   \n",
              "33  Benford’s Law, Simple Explanation   \n",
              "34                           GANshare   \n",
              "35                     GPT-4 Melodies   \n",
              "\n",
              "                                                  url  \n",
              "0   https://medium.com/towards-data-science/using-...  \n",
              "1   https://medium.com/towards-data-science/sex-an...  \n",
              "2   https://medium.com/towards-data-science/ai-mem...  \n",
              "3   https://medium.com/towards-data-science/using-...  \n",
              "4   https://medium.com/towards-data-science/clip-a...  \n",
              "5   https://medium.com/towards-data-science/ai-tun...  \n",
              "6   https://medium.com/towards-data-science/using-...  \n",
              "7   https://medium.com/towards-data-science/magnet...  \n",
              "8   https://medium.com/towards-data-science/gansca...  \n",
              "9   https://medium.com/towards-data-science/using-...  \n",
              "10  https://medium.com/towards-data-science/machin...  \n",
              "11  https://medium.com/towards-data-science/writin...  \n",
              "12  https://medium.com/towards-data-science/e-dall...  \n",
              "13  https://medium.com/towards-data-science/frost-...  \n",
              "14  https://medium.com/geekculture/portraits-from-...  \n",
              "15  https://medium.com/towards-data-science/greenl...  \n",
              "16  https://medium.com/towards-data-science/creati...  \n",
              "17  https://medium.com/towards-data-science/ganfol...  \n",
              "18  https://medium.com/towards-data-science/deep-h...  \n",
              "19  https://medium.com/towards-data-science/explor...  \n",
              "20  https://medium.com/towards-data-science/buildi...  \n",
              "21  https://medium.com/towards-data-science/i-once...  \n",
              "22  https://medium.com/towards-data-science/voxmor...  \n",
              "23  https://medium.com/towards-data-science/big-ar...  \n",
              "24  https://medium.com/geekculture/inventorbot-usi...  \n",
              "25  https://medium.com/towards-data-science/spooky...  \n",
              "26  https://medium.com/towards-data-science/explor...  \n",
              "27  https://medium.com/towards-data-science/digita...  \n",
              "28  https://medium.com/towards-data-science/writin...  \n",
              "29  https://medium.com/towards-data-science/using-...  \n",
              "30  https://medium.com/towards-data-science/muybri...  \n",
              "31  https://medium.com/towards-data-science/got-wr...  \n",
              "32  https://medium.com/towards-data-science/using-...  \n",
              "33  https://medium.com/towards-data-science/benfor...  \n",
              "34  https://medium.com/towards-data-science/gansha...  \n",
              "35  https://medium.com/towards-data-science/writin...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-679c370c-1c94-4e33-a820-7056a06c6352\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>title</th>\n",
              "      <th>subtitle</th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "      <th>nickname</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/robgon_articles_md/2023-03-07_using-o...</td>\n",
              "      <td>Using OpenCLIP for Image Search and Automatic ...</td>\n",
              "      <td>How LAION used more data and new ML training t...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>OpenClip - https://medium.com/towards-data-sci...</td>\n",
              "      <td>OpenClip</td>\n",
              "      <td>https://medium.com/towards-data-science/using-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/robgon_articles_md/2021-12-01_sex-and...</td>\n",
              "      <td>Sex and Drugs and Organic Topic Modeling</td>\n",
              "      <td>Using GPT-J to analyze the lyrics of Rock &amp; Ro...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>Organic Topic Modelling - https://medium.com/t...</td>\n",
              "      <td>Organic Topic Modelling</td>\n",
              "      <td>https://medium.com/towards-data-science/sex-an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/robgon_articles_md/2021-06-03_ai-meme...</td>\n",
              "      <td>AI-Memer: Using Machine Learning to Create Fun...</td>\n",
              "      <td>How to create new memes using images from Wiki...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>AIMemer - https://medium.com/towards-data-scie...</td>\n",
              "      <td>AIMemer</td>\n",
              "      <td>https://medium.com/towards-data-science/ai-mem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/robgon_articles_md/2021-03-01_using-o...</td>\n",
              "      <td>Using OpenAI’s CLIP to Search for Design Patents</td>\n",
              "      <td>Using natural language to search and find over...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>CLIP Patents - https://medium.com/towards-data...</td>\n",
              "      <td>CLIP Patents</td>\n",
              "      <td>https://medium.com/towards-data-science/using-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/robgon_articles_md/2022-06-09_clip-an...</td>\n",
              "      <td>CLIP and PASTE: Using AI to Create Photo Colla...</td>\n",
              "      <td>How to use ML models to extract objects from p...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>Clip-n-Paste - https://medium.com/towards-data...</td>\n",
              "      <td>Clip-n-Paste</td>\n",
              "      <td>https://medium.com/towards-data-science/clip-a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/content/robgon_articles_md/2021-09-01_ai-tune...</td>\n",
              "      <td>#Hands-on Tutorials</td>\n",
              "      <td># AI-Tunes: Creating New Songs with Artificial...</td>\n",
              "      <td>## How I fine-tuned OpenAI’s GPT-3 to generate...</td>\n",
              "      <td>AITunes - https://medium.com/towards-data-scie...</td>\n",
              "      <td>AITunes</td>\n",
              "      <td>https://medium.com/towards-data-science/ai-tun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>/content/robgon_articles_md/2022-09-06_using-a...</td>\n",
              "      <td>Using AI to Create New Comic Strips without Wr...</td>\n",
              "      <td>A tutorial on how to use GPT-3 and DALL-E to g...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>AI Comics - https://medium.com/towards-data-sc...</td>\n",
              "      <td>AI Comics</td>\n",
              "      <td>https://medium.com/towards-data-science/using-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>/content/robgon_articles_md/2021-07-05_magnet-...</td>\n",
              "      <td>#Hands-on Tutorials</td>\n",
              "      <td># MAGNet: Modern Art Generator using Deep Neur...</td>\n",
              "      <td>## How I used CLIP, SWAGAN, and a custom genet...</td>\n",
              "      <td>MAGnet - https://medium.com/towards-data-scien...</td>\n",
              "      <td>MAGnet</td>\n",
              "      <td>https://medium.com/towards-data-science/magnet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/robgon_articles_md/2021-04-01_ganscap...</td>\n",
              "      <td>#Hands-on Tutorials</td>\n",
              "      <td># GANscapes: Using AI to Create New Impression...</td>\n",
              "      <td>## How I trained StyleGAN2 ADA with 5,000 Impr...</td>\n",
              "      <td>Ganscapes - https://medium.com/towards-data-sc...</td>\n",
              "      <td>Ganscapes</td>\n",
              "      <td>https://medium.com/towards-data-science/gansca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/content/robgon_articles_md/2023-01-17_using-c...</td>\n",
              "      <td>Using ChatGPT as a Creative Writing Partner — ...</td>\n",
              "      <td>How the latest language model from OpenAI can ...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>ChatGPT Tunes - https://medium.com/towards-dat...</td>\n",
              "      <td>ChatGPT Tunes</td>\n",
              "      <td>https://medium.com/towards-data-science/using-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>/content/robgon_articles_md/2020-08-03_machine...</td>\n",
              "      <td>MachineRay: Using AI to Create Abstract Art</td>\n",
              "      <td>How I trained a GAN using public domain paintings</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>MachineRay - https://medium.com/towards-data-s...</td>\n",
              "      <td>MachineRay</td>\n",
              "      <td>https://medium.com/towards-data-science/machin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>/content/robgon_articles_md/2023-04-18_writing...</td>\n",
              "      <td>Writing Songs with GPT-4: Part 1, Lyrics</td>\n",
              "      <td>How to use the latest language model from Open...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>GPT-4 Lyrics - https://medium.com/towards-data...</td>\n",
              "      <td>GPT-4 Lyrics</td>\n",
              "      <td>https://medium.com/towards-data-science/writin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>/content/robgon_articles_md/2022-07-07_e-dall-...</td>\n",
              "      <td>E-DALL-E: Creating Digital Art with Varying As...</td>\n",
              "      <td>How to expand images generated with DALL-E Min...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>E-DALL-E - https://medium.com/towards-data-sci...</td>\n",
              "      <td>E-DALL-E</td>\n",
              "      <td>https://medium.com/towards-data-science/e-dall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>/content/robgon_articles_md/2020-12-01_frost-s...</td>\n",
              "      <td>Frost Songs: Using AI to Generate Music from P...</td>\n",
              "      <td>How Robert Frost’s words can breathe life into...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>Frost Melodies - https://medium.com/towards-da...</td>\n",
              "      <td>Frost Melodies</td>\n",
              "      <td>https://medium.com/towards-data-science/frost-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>/content/robgon_articles_md/2022-02-05_portrai...</td>\n",
              "      <td>Portraits from the Multiverse</td>\n",
              "      <td>Using Machine Learning to change the gender, e...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>Multiverse Portraits - https://medium.com/geek...</td>\n",
              "      <td>Multiverse Portraits</td>\n",
              "      <td>https://medium.com/geekculture/portraits-from-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>/content/robgon_articles_md/2022-05-09_greenli...</td>\n",
              "      <td>GreenLIT: Using GPT-J with Multi-Task Learning...</td>\n",
              "      <td>How to fine-tune an ML model to create TV show...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>GreenLit - https://medium.com/towards-data-sci...</td>\n",
              "      <td>GreenLit</td>\n",
              "      <td>https://medium.com/towards-data-science/greenl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>/content/robgon_articles_md/2021-01-01_creatin...</td>\n",
              "      <td>Creating Abstract Art with StyleGAN2 ADA</td>\n",
              "      <td>How I used Adaptive Discriminator Augmentation...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>StyleGAN Abstract Art - https://medium.com/tow...</td>\n",
              "      <td>StyleGAN Abstract Art</td>\n",
              "      <td>https://medium.com/towards-data-science/creati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>/content/robgon_articles_md/2022-01-10_ganfolk...</td>\n",
              "      <td>GANfolk: Using AI to Create Portraits of Ficti...</td>\n",
              "      <td>How to use StyleGAN2, VQGAN, and GPT-3 to synt...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>GANfolk - https://medium.com/towards-data-scie...</td>\n",
              "      <td>GANfolk</td>\n",
              "      <td>https://medium.com/towards-data-science/ganfol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>/content/robgon_articles_md/2022-03-08_deep-ha...</td>\n",
              "      <td>Deep Haiku: Teaching GPT-J to Compose with Syl...</td>\n",
              "      <td>How to generate rhythmic prose after fine-tuni...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>Deep Haiku - https://medium.com/towards-data-s...</td>\n",
              "      <td>Deep Haiku</td>\n",
              "      <td>https://medium.com/towards-data-science/deep-h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>/content/robgon_articles_md/2022-08-08_explori...</td>\n",
              "      <td>Exploring DALL-E for Digital Art Creation</td>\n",
              "      <td>I tested OpenAI’s text-to-image generator to s...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>DALL-E Art - https://medium.com/towards-data-s...</td>\n",
              "      <td>DALL-E Art</td>\n",
              "      <td>https://medium.com/towards-data-science/explor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>/content/robgon_articles_md/2020-11-01_buildin...</td>\n",
              "      <td>Building an AI 8-Ball with RoBERTa</td>\n",
              "      <td>Can an Artificial Neural Network answer yes/no...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>AI 8-Ball - https://medium.com/towards-data-sc...</td>\n",
              "      <td>AI 8-Ball</td>\n",
              "      <td>https://medium.com/towards-data-science/buildi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>/content/robgon_articles_md/2022-10-04_i-once-...</td>\n",
              "      <td>I Once Trained an AI to Rhyme, and It Took GPT...</td>\n",
              "      <td>Since the Colab was slow, I upgraded to Pro. E...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>AI Limericks - https://medium.com/towards-data...</td>\n",
              "      <td>AI Limericks</td>\n",
              "      <td>https://medium.com/towards-data-science/i-once...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>/content/robgon_articles_md/2021-05-02_voxmorp...</td>\n",
              "      <td>VoxMorphia: Using AI for Style Transfer of Son...</td>\n",
              "      <td>How I used GPT-3 to reimagine classic songs in...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>Voxmorphia - https://medium.com/towards-data-s...</td>\n",
              "      <td>Voxmorphia</td>\n",
              "      <td>https://medium.com/towards-data-science/voxmor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>/content/robgon_articles_md/2022-04-06_big-art...</td>\n",
              "      <td>BIG.art: Using Machine Learning to Create High...</td>\n",
              "      <td>How to use GLIDE and BSRGAN to create ultra-hi...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>BigArt - https://medium.com/towards-data-scien...</td>\n",
              "      <td>BigArt</td>\n",
              "      <td>https://medium.com/towards-data-science/big-ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>/content/robgon_articles_md/2021-02-01_invento...</td>\n",
              "      <td>InventorBot: Using AI to Generate New Ideas in...</td>\n",
              "      <td>How a neural network trained on the US Patent ...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>InventorBot - https://medium.com/geekculture/i...</td>\n",
              "      <td>InventorBot</td>\n",
              "      <td>https://medium.com/geekculture/inventorbot-usi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>/content/robgon_articles_md/2021-10-27_spookyg...</td>\n",
              "      <td>SpookyGAN - Rendering Scary Faces with Machine...</td>\n",
              "      <td>How to use StyleGAN 2, VQGAN, and CLIP to crea...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>SpookyGAN - https://medium.com/towards-data-sc...</td>\n",
              "      <td>SpookyGAN</td>\n",
              "      <td>https://medium.com/towards-data-science/spooky...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>/content/robgon_articles_md/2022-12-01_explori...</td>\n",
              "      <td>Exploring Midjourney V4 for Creating Digital Art</td>\n",
              "      <td>A deep dive into the features and options for ...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>Midjourney Art - https://medium.com/towards-da...</td>\n",
              "      <td>Midjourney Art</td>\n",
              "      <td>https://medium.com/towards-data-science/explor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>/content/robgon_articles_md/2022-11-09_digital...</td>\n",
              "      <td>Digital Art Showdown: Stable Diffusion, DALL-E...</td>\n",
              "      <td>A comparison of popular AI diffusion models fo...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>Digital Art Showdown - https://medium.com/towa...</td>\n",
              "      <td>Digital Art Showdown</td>\n",
              "      <td>https://medium.com/towards-data-science/digita...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>/content/robgon_articles_md/2023-05-10_writing...</td>\n",
              "      <td>Writing Songs with GPT-4: Part 2, Chords</td>\n",
              "      <td>How to use the latest large language model fro...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>GPT-4 Chords - https://medium.com/towards-data...</td>\n",
              "      <td>GPT-4 Chords</td>\n",
              "      <td>https://medium.com/towards-data-science/writin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>/content/robgon_articles_md/2023-01-04_using-c...</td>\n",
              "      <td>Using ChatGPT as a Creative Writing Partner — ...</td>\n",
              "      <td>How the latest language model from OpenAI can ...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>ChatGPT Prose - https://medium.com/towards-dat...</td>\n",
              "      <td>ChatGPT Prose</td>\n",
              "      <td>https://medium.com/towards-data-science/using-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>/content/robgon_articles_md/2023-07-25_muybrid...</td>\n",
              "      <td>Muybridge Derby: Bringing Animal Locomotion Ph...</td>\n",
              "      <td>How I used Midjourney and RunwayML to transfor...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>Muybridge Derby - https://medium.com/towards-d...</td>\n",
              "      <td>Muybridge Derby</td>\n",
              "      <td>https://medium.com/towards-data-science/muybri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>/content/robgon_articles_md/2020-09-01_got-wri...</td>\n",
              "      <td>Got Writer’s Block? It’s GPT-2 to the Rescue!</td>\n",
              "      <td>Using AI to create plot summaries of books tha...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>PlotJam - https://medium.com/towards-data-scie...</td>\n",
              "      <td>PlotJam</td>\n",
              "      <td>https://medium.com/towards-data-science/got-wr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>/content/robgon_articles_md/2023-02-07_using-c...</td>\n",
              "      <td>Using ChatGPT as a Creative Writing Partner — ...</td>\n",
              "      <td>How the latest language model from OpenAI can ...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>ChatGPT Pictures - https://medium.com/towards-...</td>\n",
              "      <td>ChatGPT Pictures</td>\n",
              "      <td>https://medium.com/towards-data-science/using-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>/content/robgon_articles_md/2020-10-02_benford...</td>\n",
              "      <td>Benford’s Law — A Simple Explanation</td>\n",
              "      <td>What Latif Nasser didn’t tell us about the “Fi...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>Benford’s Law, Simple Explanation - https://me...</td>\n",
              "      <td>Benford’s Law, Simple Explanation</td>\n",
              "      <td>https://medium.com/towards-data-science/benfor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>/content/robgon_articles_md/2021-10-06_ganshar...</td>\n",
              "      <td>GANshare: Creating and Curating Art with AI fo...</td>\n",
              "      <td>Using the CLIP and VQGAN models to generate Ch...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>GANshare - https://medium.com/towards-data-sci...</td>\n",
              "      <td>GANshare</td>\n",
              "      <td>https://medium.com/towards-data-science/gansha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>/content/robgon_articles_md/2023-06-14_writing...</td>\n",
              "      <td>Writing Songs with GPT-4: Part 3, Melodies</td>\n",
              "      <td>How to use the latest language model from Open...</td>\n",
              "      <td>Robert A. Gonsalves</td>\n",
              "      <td>GPT-4 Melodies - https://medium.com/towards-da...</td>\n",
              "      <td>GPT-4 Melodies</td>\n",
              "      <td>https://medium.com/towards-data-science/writin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-679c370c-1c94-4e33-a820-7056a06c6352')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-679c370c-1c94-4e33-a820-7056a06c6352 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-679c370c-1c94-4e33-a820-7056a06c6352');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-990a98ff-3e46-4e13-aba7-a49f97696714\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-990a98ff-3e46-4e13-aba7-a49f97696714')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-990a98ff-3e46-4e13-aba7-a49f97696714 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e73d3fd7-427a-47a3-9ad6-4b02772c18c5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e73d3fd7-427a-47a3-9ad6-4b02772c18c5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filename_fn(filename):\n",
        "  entry = df[df['filename'] == filename].iloc[0].to_dict()\n",
        "  entry.pop('filename', None)  # Remove the 'filename' key if it exists\n",
        "  return entry\n",
        "\n",
        "# load documents\n",
        "documents = SimpleDirectoryReader(\"/content/robgon_articles_md\", file_metadata=filename_fn).load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "p9llbpQJZnL5",
        "outputId": "5eeeed5a-b81e-4fc9-83e5-fc2b31b4c7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num documents:\", len(documents))\n",
        "print()\n",
        "for doc in documents[:5]:\n",
        "  print(doc.metadata)\n",
        "  print(doc.get_content())\n",
        "  print(\"****\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UPg0GQBbZsdq",
        "outputId": "6fcf5ed7-5ba9-4a83-9f25-ff67101843a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num documents: 632\n",
            "\n",
            "{'title': 'MachineRay: Using AI to Create Abstract Art', 'subtitle': 'How I trained a GAN using public domain paintings', 'author': 'Robert A. Gonsalves', 'date': 'MachineRay - https://medium.com/towards-data-science/machineray-using-ai-to-create-abstract-art-39829438076a', 'nickname': 'MachineRay', 'url': 'https://medium.com/towards-data-science/machineray-using-ai-to-create-abstract-art-39829438076a'}\n",
            "\n",
            "\n",
            "MachineRay: Using AI to Create Abstract Art\n",
            "Robert A. Gonsalves\n",
            "Aug 3, 2020\n",
            "MachineRay - https://medium.com/towards-data-science/machineray-using-ai-to-create-abstract-art-39829438076a\n",
            "For the past three months, I have been exploring the latest techniques in Artificial Intelligence (AI) and Machine Learning (ML) to create abstract art. During my investigation, I learned that three things are needed to create abstract paintings: (A) source images, (B) an ML model, and (C) a lot of time to train the model on a high-end GPU. Before I discuss my work, let’s take a look at some prior research.\n",
            "This is the first part of my series of articles on how AI can be used for creative endeavors. The second part is on how to use ML to generate plots for new stories, available  here .\n",
            "\n",
            "****\n",
            "{'title': 'MachineRay: Using AI to Create Abstract Art', 'subtitle': 'How I trained a GAN using public domain paintings', 'author': 'Robert A. Gonsalves', 'date': 'MachineRay - https://medium.com/towards-data-science/machineray-using-ai-to-create-abstract-art-39829438076a', 'nickname': 'MachineRay', 'url': 'https://medium.com/towards-data-science/machineray-using-ai-to-create-abstract-art-39829438076a'}\n",
            "\n",
            "\n",
            "Background\n",
            "Warren McCulloch and Walter Pitts created a computational model for Neural Networks (NNs) back in 1943[1]. Their work led to research of both the biological processing in brains and the use of NNs for AI. Richard Nagyfi discusses the differences between Artificial Neural Networks (ANNs) and biological brains in this  post . He describes an apt analogy that I will summarize here:  ANNs are to brains as planes are to birds . Although the development of these technologies was inspired by biology, the actual implementations are very different!\n",
            "Both ANNs and biological brains learn from external stimuli to understand things and predict outcomes. One of the key differences is that ANNs work with floating-point numbers and not just binary firing of neurons.  With ANNs it’s numbers in and numbers out.\n",
            "The diagram below shows the structure of a typical ANN. The inputs on the left are the numerical values that contain the incoming stimuli. The input layer is connected to one or more hidden layers that contain the memory of prior learning. The output layer, in this case just one number, is connected to each of the nodes in the hidden layer.\n",
            "Each of the internal arrows represents numerical weights that are used as multipliers to modify the numbers in the layers as they get processed in the network from left to right. The system is trained with a dataset of input values and expected output values. The weights are initially set to random values. For the training process, the system runs through the training set multiple times, adjusting the weights to achieve the expected outputs. Eventually, the system will not only predict the outputs correctly from the training set, but it will also be able to predict outputs for unseen input values. This is the essence of Machine Learning (ML).  The intelligence is in the weights . A more detailed discussion of the training process for ANNs can be found in Conor McDonald’s post,  here .\n",
            "\n",
            "****\n",
            "{'title': 'MachineRay: Using AI to Create Abstract Art', 'subtitle': 'How I trained a GAN using public domain paintings', 'author': 'Robert A. Gonsalves', 'date': 'MachineRay - https://medium.com/towards-data-science/machineray-using-ai-to-create-abstract-art-39829438076a', 'nickname': 'MachineRay', 'url': 'https://medium.com/towards-data-science/machineray-using-ai-to-create-abstract-art-39829438076a'}\n",
            "\n",
            "\n",
            "Generative Adversarial Networks\n",
            "In 2014, Ian Goodfellow and seven coauthors at the Université de Montréal presented a  paper  on Generative Adversarial Networks (GANs)[2].  They came up with a way to train two ANNs that effectively compete with each other to create content like photos, songs, prose, and yes, paintings.  The first ANN is called the Generator and the second is called the Discriminator. The Generator is trying to create realistic output, in this case, a color painting. The Discriminator is trying to discern real paintings from the training set as opposed to fake paintings from the generator. Here’s what a GAN architecture looks like.\n",
            "A series of random noise is fed into the Generator, which then uses its trained weights to generate the resultant output, in this case, a color image. The Discriminator is trained by alternating between processing real paintings, with an expected output of 1 and fake paintings, with an expected output of -1. After each painting is sent to the Discriminator, it sends back detailed feedback about why the painting is not real, and the Generator adjusts its weights with this new knowledge to try and do better the next time.  The two networks in the GAN are effectively trained together in an adversarial fashion . The Generator gets better at trying to pass off a fake image as real, and the Discriminator gets better at determining which input is real, and which is fake. Eventually, the Generator gets pretty good at generating realistic-looking images. You can read more about GANs, and the math they use, in Shweta Goyal’s post  here .\n",
            "\n",
            "****\n",
            "{'title': 'MachineRay: Using AI to Create Abstract Art', 'subtitle': 'How I trained a GAN using public domain paintings', 'author': 'Robert A. Gonsalves', 'date': 'MachineRay - https://medium.com/towards-data-science/machineray-using-ai-to-create-abstract-art-39829438076a', 'nickname': 'MachineRay', 'url': 'https://medium.com/towards-data-science/machineray-using-ai-to-create-abstract-art-39829438076a'}\n",
            "\n",
            "\n",
            "Improved GANs for Large Images\n",
            "Although the basic GAN described above works well with small images (i.e. 64x64 pixels), there are issues with larger images (i.e. 1024x1024 pixels). The basic GAN architecture has difficulty converging on good results for large images due to the unstructured nature of the pixels. It can’t see the forest from the trees. Researchers at NVIDIA developed a series of improved methods that allow for the training of GANs with larger images. The first is called “ Progressive Growing of GANs ” [3].\n",
            "> The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality. —  Tero Karras  et. al., NVIDIA\n",
            "\n",
            "\n",
            "The team at NVIDIA continued their work on using GANs to generate large, realistic images, naming their architecture  StyleGAN  [4]. They started with their Progressive Growing of GANs as a base model and added a Style Mapping Network, which injects style information at various resolutions into the Generator Network.\n",
            "The team further improved the image creation results with  StyleGAN 2, allowing the GAN to efficiently create high-quality images with fewer unwanted artifacts [5]. You can read more about these developments in Akria’s post, “ From GAN basic to StyleGAN2 ”.\n",
            "\n",
            "****\n",
            "{'title': 'MachineRay: Using AI to Create Abstract Art', 'subtitle': 'How I trained a GAN using public domain paintings', 'author': 'Robert A. Gonsalves', 'date': 'MachineRay - https://medium.com/towards-data-science/machineray-using-ai-to-create-abstract-art-39829438076a', 'nickname': 'MachineRay', 'url': 'https://medium.com/towards-data-science/machineray-using-ai-to-create-abstract-art-39829438076a'}\n",
            "\n",
            "\n",
            "Prior Work to Create Art with GANs\n",
            "Researchers have been looking to use GANs to create art since the GAN was introduced in 2014. A description of a system called ArtGAN was published in 2017 by Wei Ren Tan et. al. from Shinshu University, Nagano, Japan [6]. Their  paper  proposes to extend GANs…\n",
            "> … to synthetically generate more challenging and complex images such as artwork that have abstract characteristics. This is in contrast to most of the current solutions that focused on generating natural images such as room interiors, birds, flowers and faces. —  Wei Ren Tan  et. al., Shinshu University\n",
            "\n",
            "\n",
            "A broader survey of using GANs to create art was conducted by Drew Flaherty for his Masters Thesis at the Queensland University of Technology in Brisbane, Australia [7]. He experimented with various GANs including basic GANs,  CycleGAN  [8],  BigGAN  [9],  Pix2Pix , and StyleGAN. Of everything he tried, he liked StyleGAN the best.\n",
            "> The best visual result from the research came from StyleGAN. … Visual quality of the outputs were relatively high considering the model was only partially trained, with progressive improvements from earlier iterations showing more defined lines, textures and forms, sharper detail, and more developed compositions overall. —  Drew Flaherty , Queensland University of Technology\n",
            "\n",
            "\n",
            "For his experiments, Flaherty used a large library of artwork gleaned from various sources, including  WikiArt.org , the  Google Arts Project ,  Saatchi Art , and  Tumblr  blogs. He noted that not all of the source images are in the public domain, but he discusses the doctrine of fair use and its implications on ML and AI.\n",
            "\n",
            "****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(documents)\n",
        "select_documents = documents[:100]\n",
        "print(\"Num documents:\", len(documents))\n",
        "print()\n",
        "for doc in select_documents[:5]:\n",
        "  print(doc.metadata)\n",
        "  print(doc.get_content())\n",
        "  print(\"****\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l9Lw-rz5vLKw",
        "outputId": "6e5647f7-97c2-49fe-fa3d-850eb2ceb35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num documents: 632\n",
            "\n",
            "{'title': 'Writing Songs with GPT-4: Part 2, Chords', 'subtitle': 'How to use the latest large language model from OpenAI to help compose chords for original songs', 'author': 'Robert A. Gonsalves', 'date': 'GPT-4 Chords - https://medium.com/towards-data-science/writing-songs-with-gpt-4-part-2-chords-173cfda0e5a1', 'nickname': 'GPT-4 Chords', 'url': 'https://medium.com/towards-data-science/writing-songs-with-gpt-4-part-2-chords-173cfda0e5a1'}\n",
            "\n",
            "\n",
            "Source Code\n",
            "The source code for this project is available on  GitHub .\n",
            "\n",
            "****\n",
            "{'title': '#Hands-on Tutorials', 'subtitle': '# MAGNet: Modern Art Generator using Deep Neural Networks', 'author': '## How I used CLIP, SWAGAN, and a custom genetic algorithm to create modern paintings from text descriptions', 'date': 'MAGnet - https://medium.com/towards-data-science/magnet-modern-art-generator-using-deep-neural-networks-57537457bb7', 'nickname': 'MAGnet', 'url': 'https://medium.com/towards-data-science/magnet-modern-art-generator-using-deep-neural-networks-57537457bb7'}\n",
            "\n",
            "\n",
            "Using CLIP to Filter the Images for Training\n",
            "After cropping the images, I ended up having over 12,000 paintings to work with. That’s enough to train a GAN, but not all of the paintings are good. Just because a painter is tagged on WikiArt as being “modern” doesn’t mean that all of their works are good examples of modern painting. I used CLIP to filter the images as I did in my GANscapes project to winnow down the dataset.\n",
            "OpenAI designed their two models for CLIP, an image and text encoder, to perform semantic searches. They trained the two models on a dataset of images with corresponding phrases. The goal of the models is to have the encoded images match the encoded phrases.\n",
            "Once trained, the image encoder system converts images to embeddings, lists of 512 floating-point numbers that capture the images’ general features. The text encoder converts a text phrase to similar embedding that can be compared to image embeddings for a semantic search.\n",
            "For MAGnet, I compare the embedding from the phrase “modern painting” to the embeddings from the paintings to find the top 10,000 images that best match the phrase. The source code is in the Colab  here .\n",
            "Here are some examples that didn’t make the cut as modern paintings. The first two probably scored lower because they don't have a lot of contrast. The third seems more like a drawing than a painting.\n",
            "\n",
            "****\n",
            "{'title': 'Using AI to Create New Comic Strips without Writing Any Code', 'subtitle': 'A tutorial on how to use GPT-3 and DALL-E to generate original content for the funny pages', 'author': 'Robert A. Gonsalves', 'date': 'AI Comics - https://medium.com/towards-data-science/using-ai-to-create-new-comic-strips-without-writing-any-code-cc669bb317a7', 'nickname': 'AI Comics', 'url': 'https://medium.com/towards-data-science/using-ai-to-create-new-comic-strips-without-writing-any-code-cc669bb317a7'}\n",
            "\n",
            "\n",
            "Final Thoughts\n",
            "Comparing the two systems, I found that GPT-3 does a much better job generating the text than DALL-E does for the artwork. Although the initial images for the comics look OK as concept renderings, they need some cleanup to be used in production. But the main problem is DALL-E doesn’t generate characters consistently for the comic strip. The primary limitation stems from the 1024x1024 image size in DALL-E. Note that OpenAI  recently added  a new “outpainting” feature to more easily add to generated images. However, the new feature only works in a piecemeal fashion. It only ever considers a 1024x1024 frame for image generation. The system would need an “upload reference frames” feature to generate visual elements consistently, like comic strip characters.\n",
            "\n",
            "****\n",
            "{'title': 'Using AI to Create New Comic Strips without Writing Any Code', 'subtitle': 'A tutorial on how to use GPT-3 and DALL-E to generate original content for the funny pages', 'author': 'Robert A. Gonsalves', 'date': 'AI Comics - https://medium.com/towards-data-science/using-ai-to-create-new-comic-strips-without-writing-any-code-cc669bb317a7', 'nickname': 'AI Comics', 'url': 'https://medium.com/towards-data-science/using-ai-to-create-new-comic-strips-without-writing-any-code-cc669bb317a7'}\n",
            "\n",
            "\n",
            "Mark Madness\n",
            "For the Mark Madness comic, I used this prompt, “A comic set in a basketball court with two characters wearing a red uniform, Mark, a talented college basketball player, and Enrique, an egotistical teammate.” Here are the four images DALL-E created.\n",
            "I liked the second one, but I needed to clean it up a bit in Photoshop. And I added the title and the dialog generated by GPT-3, replacing the gibberish text in the word balloons. Here are the before and after images.\n",
            "This is kinda like one of those visual puzzles where you need to find the ten differences. Can you spot them all? 🙂\n",
            "I like the overall look of the comic, with some lovely details like the red vertical bar that matches the team color. The eyes of the characters, however, do not match at all. I used a little trick in Photoshop to replicate Mark’s right eye and Enrique’s left eye. I used the Comic Sans font for the dialog, of course.\n",
            "\n",
            "****\n",
            "{'title': 'BIG.art: Using Machine Learning to Create High-Res Fine Art', 'subtitle': 'How to use GLIDE and BSRGAN to create ultra-high-resolution digital paintings with fine details', 'author': 'Robert A. Gonsalves', 'date': 'BigArt - https://medium.com/towards-data-science/big-art-using-machine-learning-to-create-high-res-fine-art-7dd695f99788', 'nickname': 'BigArt', 'url': 'https://medium.com/towards-data-science/big-art-using-machine-learning-to-create-high-res-fine-art-7dd695f99788'}\n",
            "\n",
            "\n",
            "Source Code\n",
            "The  source code  for this project is available on GitHub. I am releasing the sources under the CC BY-SA license. You can create your own images using this  Google Colab .\n",
            "If you use this code to create new images, please give attribution like this: This image was created with  BIG.art   by  Robert A. Gonsalves .\n",
            "\n",
            "****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms import OpenAI\n",
        "llm = OpenAI(model=\"gpt-4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wsd-musSeXaF",
        "outputId": "ca45cf20-2006-41b0-dbf6-f140b364f7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\"Ask one question about the reference material and answer it.\n",
        "Don't use the phrase 'reference material.' Instead, use the article's title or the project's nickname.\n",
        "In the question don't use the phrase 'the author'. Use 'Robert' or 'Robert A. Gonsalves' instead.\n",
        "In the answer, refer to the author as 'he/him/his' if his name was used in the question.\n",
        "Use the format:\n",
        "q: <question>\n",
        "a: <answer>\"\"\"\n",
        "\n",
        "for doc in select_documents[:5]:\n",
        "  prompt =\"Reference:\\n\" + doc.get_metadata_str() + \"\\n\" + doc.get_content() + \"\\n\\n\" + prefix\n",
        "  # print(prompt)\n",
        "  # print(\"****\")\n",
        "  response = llm.complete(prompt)\n",
        "  print(response)\n",
        "  print(\"****\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "4SZLOAqftl4x",
        "outputId": "abafb03a-fe02-4589-eafb-31e8c4c0348e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is the main focus of Robert A. Gonsalves' article \"Writing Songs with GPT-4: Part 2, Chords\"?\n",
            "A: In his article, Robert A. Gonsalves discusses how to use the latest large language model from OpenAI, GPT-4, to assist in composing chords for original songs. He provides insights into the capabilities of this AI model in the field of music composition.\n",
            "****\n",
            "Q: How does Robert use CLIP to filter images for the MAGnet project?\n",
            "A: Robert uses CLIP, a model designed by OpenAI, to filter images for the MAGnet project. He uses the image and text encoder models of CLIP to perform semantic searches. These models are trained on a dataset of images with corresponding phrases, with the goal of having the encoded images match the encoded phrases. The image encoder system converts images to embeddings, which are lists of 512 floating-point numbers that capture the images’ general features. The text encoder converts a text phrase to a similar embedding that can be compared to image embeddings for a semantic search. For MAGnet, Robert compares the embedding from the phrase “modern painting” to the embeddings from the paintings to find the top 10,000 images that best match the phrase.\n",
            "****\n",
            "Q: What is the main limitation of DALL-E in generating comic strips, according to Robert A. Gonsalves?\n",
            "A: According to him, the main limitation of DALL-E in generating comic strips is its inability to generate characters consistently. This issue primarily stems from the 1024x1024 image size in DALL-E. Even though OpenAI recently added a new “outpainting” feature to more easily add to generated images, it only works in a piecemeal fashion and only ever considers a 1024x1024 frame for image generation. He suggests that the system would need an “upload reference frames” feature to generate visual elements consistently, like comic strip characters.\n",
            "****\n",
            "Q: How did Robert A. Gonsalves modify the images generated by DALL-E for the Mark Madness comic?\n",
            "A: Robert cleaned up the selected image in Photoshop, added the title, and replaced the gibberish text in the word balloons with dialog generated by GPT-3. He also used a trick in Photoshop to replicate Mark’s right eye and Enrique’s left eye to make them match. He used the Comic Sans font for the dialog.\n",
            "****\n",
            "Q: What machine learning tools does Robert A. Gonsalves use in the BigArt project to create ultra-high-resolution digital paintings?\n",
            "A: In the BigArt project, he uses GLIDE and BSRGAN to create ultra-high-resolution digital paintings with fine details.\n",
            "****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create an empty DataFrame with the desired columns\n",
        "df_qa = pd.DataFrame(columns=['doc_metadata', 'doc_content', 'question', 'answer'])\n",
        "\n",
        "for i, doc in enumerate(select_documents):\n",
        "    prompt = \"Reference\\n\" + str(doc.metadata) + \"\\n\" + doc.get_content() + \"\\n\\n\" + prefix\n",
        "\n",
        "    # Assuming llm.complete(prompt) returns a string in the format \"Q: <question>\\nA: <answer>\"\n",
        "    response = llm.complete(prompt)\n",
        "\n",
        "    # Split the response into question and answer parts\n",
        "    q, a = response.text.split(\"\\n\")\n",
        "\n",
        "    # Extract the actual question and answer text\n",
        "    question = q[3:].strip()\n",
        "    answer = a[3:].strip()\n",
        "\n",
        "    print(\"entry:\", i)\n",
        "    print(\"q:\", question)\n",
        "    print(\"a:\", answer)\n",
        "    print(\"****\")\n",
        "\n",
        "    # Create a new DataFrame for the current row and concatenate it to the main DataFrame\n",
        "    new_row = pd.DataFrame({\n",
        "        'doc_metadata': [str(doc.metadata)],\n",
        "        'doc_content': [doc.get_content().strip()],\n",
        "        'question': [question],\n",
        "        'answer': [answer]\n",
        "    })\n",
        "    df_qa = pd.concat([df_qa, new_row], ignore_index=True)\n",
        "\n",
        "# Now, df_qa contains the desired data and can be used for further analysis or saved to a file.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4PhIAOPDwJER",
        "outputId": "61b28580-2812-406c-8f4a-5b2a676de286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entry: 0\n",
            "q: What is the main objective of Robert A. Gonsalves' project 'GPT-4 Chords'?\n",
            "a: The main objective of his project 'GPT-4 Chords' is to demonstrate how to use the latest large language model from OpenAI, GPT-4, to help compose chords for original songs.\n",
            "****\n",
            "entry: 1\n",
            "q: How did Robert use CLIP to filter the images for the MAGnet project?\n",
            "a: Robert used CLIP to filter the images by comparing the embedding from the phrase \"modern painting\" to the embeddings from the paintings. This allowed him to find the top 10,000 images that best matched the phrase \"modern painting\". This was done to ensure that the images used for training were good examples of modern painting.\n",
            "****\n",
            "entry: 2\n",
            "q: What are the limitations Robert A. Gonsalves found in using DALL-E for generating artwork for comic strips?\n",
            "a: Robert found that while DALL-E could generate concept renderings for the comic strips, the images often required cleanup before they could be used in production. He also noted that DALL-E struggled with generating characters consistently across the comic strip. This was primarily due to the system's limitation of only considering a 1024x1024 frame for image generation. Even with the new \"outpainting\" feature, which allows for easier addition to generated images, the system still operates in a piecemeal fashion. He suggested that the system would benefit from an \"upload reference frames\" feature to generate visual elements, like comic strip characters, more consistently.\n",
            "****\n",
            "entry: 3\n",
            "q: How did Robert A. Gonsalves modify the images created by DALL-E for the Mark Madness comic?\n",
            "a: Robert cleaned up the images in Photoshop, added the title, and replaced the gibberish text in the word balloons with dialog generated by GPT-3. He also used a trick in Photoshop to replicate the eyes of the characters Mark and Enrique, and used the Comic Sans font for the dialog.\n",
            "****\n",
            "entry: 4\n",
            "q: What machine learning tools does Robert A. Gonsalves use to create ultra-high-resolution digital paintings?\n",
            "a: He uses GLIDE and BSRGAN to create these high-resolution digital paintings.\n",
            "****\n",
            "entry: 5\n",
            "q: How did Robert A. Gonsalves use GPT-4 to create melodies for a song?\n",
            "a: Robert interacted with GPT-4 by asking it to compose a melody for a song, one part at a time. He provided the lyrics and asked the AI to create a melody in guitar tab format, with one note for each syllable. GPT-4, being a text-based model, provided an example of how the chords could be put to a simple melody using guitar tab format. Robert then adjusted the melody to suit the rhythm of the song. He also wrote Python code to convert the guitar tabs to MIDI files, so he could hear how the melody sounded.\n",
            "****\n",
            "entry: 6\n",
            "q: What is the main focus of Robert A. Gonsalves' article \"Writing Songs with GPT-4: Part 2, Chords\"?\n",
            "a: In his article, Robert A. Gonsalves discusses how to use the latest large language model from OpenAI, GPT-4, to help compose chords for original songs.\n",
            "****\n",
            "entry: 7\n",
            "q: How does Robert A. Gonsalves describe the process of generating images using StyleCLIP in his article \"SpookyGAN - Rendering Scary Faces with Machine Learning\"?\n",
            "a: In his article, Robert explains that StyleCLIP works by iteratively changing the input into StyleGAN 2 to steer the generated image to match a text prompt as measured by CLIP. The process begins with the average image defined by the StyleGAN 2 model, which is sent into the CLIP image encoder. The text prompt is sent into the CLIP text encoder, and the two embeddings are compared. The StyleCLIP optimizer then steers the generator to create images that get successively closer to the features described in the prompt. This is done by minimizing the difference between the image embedding and the text embedding with each iteration. After about 40 passes, the image will start to look like what the prompt describes.\n",
            "****\n",
            "entry: 8\n",
            "q: What future research does Robert A. Gonsalves suggest in his article \"Benford’s Law — A Simple Explanation\"?\n",
            "a: In his article, he suggests that future research could involve investigating how adherence to lognormal distributions and compliance with Benford’s Law might be related when the datasets do not closely match the ideals. He believes that these tools, used together, could assist in identifying any underlying reasons for discrepancies in the data.\n",
            "****\n",
            "entry: 9\n",
            "q: What was the main focus of the Ganscapes project by Robert A. Gonsalves?\n",
            "a: The main focus of the Ganscapes project was to experiment with Generative Adversarial Networks (GANs) to create Impressionist landscape paintings. This was a shift from his previous projects which focused on creating abstract art using image augmentation.\n",
            "****\n",
            "entry: 10\n",
            "q: How does the Generator in the MachineRay project improve its ability to create realistic images?\n",
            "a: The Generator in the MachineRay project improves its ability to create realistic images through feedback from the Discriminator. After each painting is sent to the Discriminator, it sends back detailed feedback about why the painting is not real. The Generator then adjusts its weights with this new knowledge to try and do better the next time. This adversarial training process continues until the Generator gets pretty good at generating realistic-looking images.\n",
            "****\n",
            "entry: 11\n",
            "q: What metrics did Robert use to gauge the esthetics of generated art in his exploration of Midjourney V4?\n",
            "a: In his exploration of Midjourney V4, he used a technique involving the CLIP model by OpenAI to estimate esthetic quality. He compared an image embedding to the embeddings of positive and negative text prompts, such as “bad art” and “good art.” The difference in similarity was used to produce results. He also calculated a prompt similarity metric to see how well the image matched the prompt.\n",
            "****\n",
            "entry: 12\n",
            "q: What does the AI 8-Ball built by Robert A. Gonsalves do?\n",
            "a: The AI 8-Ball built by him is designed to answer yes/no questions using the power of the Internet and current Machine Learning techniques. It provides both a percentage no-to-yes answer and a percentage confidence level as outputs.\n",
            "****\n",
            "entry: 13\n",
            "q: What is the main purpose of the PlotJam project as described by Robert A. Gonsalves?\n",
            "a: The main purpose of the PlotJam project, as described by Robert, is to use AI, specifically GPT-2, to generate plot summaries for books that don't exist yet. This can be particularly useful for writers who are experiencing writer's block and need some inspiration to get started.\n",
            "****\n",
            "entry: 14\n",
            "q: What was the purpose of the VoxMorphia project by Robert A. Gonsalves?\n",
            "a: The purpose of the VoxMorphia project by Robert was to use AI, specifically GPT-3, to reimagine classic songs in the style of different artists like Bob Marley, Radiohead, and Megan Thee Stallion.\n",
            "****\n",
            "entry: 15\n",
            "q: What inspired Robert A. Gonsalves to create abstract art using StyleGAN2 ADA?\n",
            "a: Robert was inspired by the progression of many abstract painters who started by painting figurative subjects, like people and landscapes, and then moved to abstract art. He mentioned the sequences of paintings by Mondrian, Klee, and Kandinsky as examples of this progression. This led him to use StyleGAN2 ADA to generate improved abstract paintings with AI.\n",
            "****\n",
            "entry: 16\n",
            "q: What did Robert A. Gonsalves do to improve the speed of his AI training for rhyming?\n",
            "a: To improve the speed of his AI training for rhyming, he upgraded to Pro from Colab, as the latter was slow.\n",
            "****\n",
            "entry: 17\n",
            "q: What was the main challenge faced by Jianyou Wang and his team when using GPT-2 for generating limericks?\n",
            "a: The main challenge they faced was that GPT-2 tended to generate long sentences that exceeded the syllable limit for limericks. To meet the syllable constraint, they had to truncate the generated sentences, which resulted in lines that did not end correctly.\n",
            "****\n",
            "entry: 18\n",
            "q: What was the purpose of Robert A. Gonsalves' project, MachineRay?\n",
            "a: The purpose of MachineRay was to use artificial intelligence, specifically a GAN (Generative Adversarial Network), to create abstract art. Robert trained the AI using public domain paintings.\n",
            "****\n",
            "entry: 19\n",
            "q: How does Robert use the KeyBERT module in the GreenLit project?\n",
            "a: In the GreenLit project, Robert uses the KeyBERT module to extract themes from movie and TV show summaries. He applies this to datasets he found on Kaggle, which include a large list of movie plot summaries and a collection of summaries of streaming shows. The extracted themes, along with genres, titles, and summaries, are then used to train the GPT-J model to create new titles and summaries.\n",
            "****\n",
            "entry: 20\n",
            "q: How did Robert interpret the multiple notes generated by GPT-4 for the pre-chorus melody?\n",
            "a: Robert interpreted the multiple notes as held notes, meaning a string of four eighth notes could be played as one half note. This interpretation was due to the limitation of the guitar tab format, which does not express note lengths. After converting some of the repeated notes to single ones with longer durations, he found the melody to be more pleasing.\n",
            "****\n",
            "entry: 21\n",
            "q: How did Robert diversify the character names in the scripts generated by GreenLit?\n",
            "a: Robert diversified the character names by swapping out the names from the Friends scripts used in the training dataset. He used a list of first names collected by the US Social Security Office to replace the original character names. For instance, Ross was changed to Lucas, Chandler to Antonio, Joey to Eddie, Rachel to Charlotte, Phoebe to Stella, and Monica to Luciana. He also replaced any references to “Central Perk” with “Coffee Shop” to further remove the association with Friends.\n",
            "****\n",
            "entry: 22\n",
            "q: How did Robert A. Gonsalves improve the quality of the Haikus in the dataset for the Deep Haiku project?\n",
            "a: For the Deep Haiku project, he noticed that the Haikus in the first dataset were all lowercase and without punctuation. To improve the text quality, he decided to add uppercase letters and punctuation using the FastPunct module. He also applied the same process to the second dataset for consistency, even though some of the Haikus already had casing and punctuation. This resulted in a combined dataset of over 150K Haikus.\n",
            "****\n",
            "entry: 23\n",
            "q: What motivated Robert to fine-tune OpenAI's GPT-3 for music generation?\n",
            "a: Robert was motivated by the lack of quality in AI-generated music. He found most of the AI-generated music to be either too complicated, rambling, too simple, or repetitive. Given the advancements in AI-based content creation for other forms of media, he was inspired to use OpenAI's GPT-3 to create music that was more pleasing and had a global structure.\n",
            "****\n",
            "entry: 24\n",
            "q: How does the MAGnet project use a genetic algorithm to create modern paintings from text descriptions?\n",
            "a: The MAGnet project uses a genetic algorithm in conjunction with CLIP and SWAGAN to generate modern paintings from text descriptions. The process begins by encoding the text query using CLIP to get the features. An initial population of images is generated, and the genetic algorithm is run for a certain number of steps. The images are generated using SWAGAN and their features are encoded using CLIP. The images are then ranked and the top four are selected. These top four images undergo a process of recombination and mutation to create new images. This process is repeated for a set number of generations. The final result is a unique image that is based on the initial text description.\n",
            "****\n",
            "entry: 25\n",
            "q: What are some of the limitations Robert A. Gonsalves identified in using ChatGPT for music composition?\n",
            "a: Robert identified that while ChatGPT can generate chord progressions and provide commentary on its choices, it occasionally makes mistakes such as giving contradictory and seemingly incorrect recommendations for chords. He also noted that the system has a long way to go in terms of composing melodies, as his initial attempt at creating a melody for a blues song did not yield satisfactory results.\n",
            "****\n",
            "entry: 26\n",
            "q: What future applications does Robert A. Gonsalves see for the VQGAN model?\n",
            "a: Robert envisions using VQGAN as a general inpainting tool in future projects. He believes that despite the system quantizing the masked area to 16x16 pixel blocks, it might be possible to blend back in both the original latent vectors and the original pixels outside the masked regions. Furthermore, with the use of CLIP as a guiding text encoder, he suggests that it might be possible to perform functions like \"draw a party hat on the pug.\"\n",
            "****\n",
            "entry: 27\n",
            "q: How does Robert A. Gonsalves use the Remix mode in Midjourney Art?\n",
            "a: Robert A. Gonsalves uses the Remix mode in Midjourney Art to modify the text prompt when creating variations of an image. He demonstrates this by adding different time periods like \"1880s\", \"1950s\", and \"future\" to the prompts, resulting in the system rendering the image with distinctive visual looks associated with the specified time periods.\n",
            "****\n",
            "entry: 28\n",
            "q: What does Robert use as an example to explain how distributions follow Benford's Law?\n",
            "a: Robert uses the example of an online statistics class with 10,000 students. Each student is asked to roll a six-sided die and enter their result into a spreadsheet. The expected result would be about 1,666 rolls per outcome, which is an approximation of an even distribution.\n",
            "****\n",
            "entry: 29\n",
            "q: How does Robert A. Gonsalves address the issue of repetition in the plot summaries generated by PlotJam?\n",
            "a: Robert addresses this issue by creating a Python function that identifies and flags any repeated phrases in the generated plot summaries. This function works by detecting if a phrase of a given length appears more than once in the input. He uses a phrase length of five to filter out repetitive plot summaries, thus enhancing the quality and uniqueness of the generated content.\n",
            "****\n",
            "entry: 30\n",
            "q: What is the primary function of DALL-E Mini as described by Robert A. Gonsalves?\n",
            "a: DALL-E Mini, as explained by Robert, is a free, open-source text-to-image generator. It uses a pair of trained BERT Transformers to convert text into latent vectors, which are then used by VQGAN to render images. The system does not generate the images iteratively but transforms the text directly into vectors for image rendering. He also mentions that the model is relatively small with 400 million parameters and was trained on 15 million images.\n",
            "****\n",
            "entry: 31\n",
            "q: How did Robert A. Gonsalves use GPT-4 to create chords for a song?\n",
            "a: Robert A. Gonsalves used GPT-4 to generate chords for a song by inputting the lyrics and asking the model to provide the chords. He then adjusted the formatting by asking the model to place the chords in line with the lyrics. He also used GPT-4 to determine the key of the song. After generating the chords, he used a commercial app called Band-in-a-Box to hear what the chords sounded like with the lyrics.\n",
            "****\n",
            "entry: 32\n",
            "q: What did Robert A. Gonsalves do to improve the speed of his AI Limericks project?\n",
            "a: To improve the speed of his AI Limericks project, he upgraded to Pro on Colab.\n",
            "****\n",
            "entry: 33\n",
            "q: What is the typical song structure that GPT-4 seems to follow when composing songs, according to Robert A. Gonsalves?\n",
            "a: According to him, GPT-4 typically follows a formulaic structure when composing songs. This structure often includes a verse (A), chorus (B), verse (A), chorus (B), bridge (C), chorus (B), and an outro (A). It also consistently uses a four-chord pattern for the song parts.\n",
            "****\n",
            "entry: 34\n",
            "q: How does Robert use the GLIDE image generator in the BIG.art project?\n",
            "a: In the BIG.art project, Robert uses the GLIDE image generator to take in a text prompt and produce a series of seven 64x64 images. The system attempts to depict what is described in the prompt. He then feeds the images and the prompt into the GLIDE upsampler that increases the resolution to 256x256. The system was trained to use the prompt to help add detail when resizing up.\n",
            "****\n",
            "entry: 35\n",
            "q: What was the purpose of Robert A. Gonsalves' project, VoxMorphia?\n",
            "a: The purpose of VoxMorphia was to use AI, specifically GPT-3, to transform the lyrics of public domain songs into the lyrical styles of various artists, including Bob Marley, Thom Yorke from Radiohead, and Megan Thee Stallion. He aimed to showcase a range of styles through this experiment.\n",
            "****\n",
            "entry: 36\n",
            "q: How did Robert manage to continue the training of the GANscapes system on Google Colab Pro despite its 24-hour timeout limit?\n",
            "a: Robert managed to continue the training of the GANscapes system on Google Colab Pro by saving the results on his Google Drive. This allowed him to pick up where he left off after each timeout. He also modified the StyleGAN2 ADA to allow the ADA variable 'p', which determines the level of image augmentation during training, to be set when the augmentation is set to ADA. This prevented the system from having to climb back up to around 0.2 each day, thus saving time and resources.\n",
            "****\n",
            "entry: 37\n",
            "q: What does Robert A. Gonsalves think about the quality and resolution of the images generated by DALL-E?\n",
            "a: He believes that the quality and resolution of the images generated by DALL-E are excellent.\n",
            "****\n",
            "entry: 38\n",
            "q: What was the main objective of Robert A. Gonsalves in the Muybridge Derby project?\n",
            "a: In the Muybridge Derby project, Robert A. Gonsalves aimed to transform Eadweard Muybridge’s photo sequences into high-resolution videos using Midjourney and RunwayML, two artificial intelligence tools.\n",
            "****\n",
            "entry: 39\n",
            "q: How does Robert A. Gonsalves create a video using the SpookyGAN system?\n",
            "a: Robert creates a video using the SpookyGAN system by using a generic text prompt like “nightmare” and reducing the learning rate of the optimizer to 1%. The system starts with the modified image created by VQGAN and is sent into the CLIP image encoder. The system runs for 300 frames, generating 10 seconds of video at 30 frames per second. He then uses the ffmpeg codec to generate an mp4 movie file.\n",
            "****\n",
            "entry: 40\n",
            "q: What was the purpose of Robert A. Gonsalves' project, Voxmorphia?\n",
            "a: The purpose of his project, Voxmorphia, was to demonstrate that AI can be used to generate new text based on the style of another writer. He aimed to show that AI-generated text can be used in creative ways, such as reimagining classic songs in the style of different artists.\n",
            "****\n",
            "entry: 41\n",
            "q: How does the OpenCLIP system perform in terms of searching for images in a large dataset?\n",
            "a: According to Robert A. Gonsalves, the OpenCLIP system performs well when it comes to searching for images in a large dataset. He also mentions that the new techniques for embedding math provide expert tools to help people find the perfect shot.\n",
            "****\n",
            "entry: 42\n",
            "q: What was Robert's motivation behind training an AI to create limericks?\n",
            "a: Robert A. Gonsalves was inspired by the historical use of limericks, often filled with humor and sometimes veering into R-rated territory. He wanted to see if an AI system could replicate this unique form of poetry.\n",
            "****\n",
            "entry: 43\n",
            "q: What is the main objective of Robert A. Gonsalves' project, GreenLit?\n",
            "a: The main objective of GreenLit is to fine-tune a machine learning model, specifically GPT-J, with multi-task learning to create new screenplays. This includes generating new titles, plot summaries, and scripts for TV shows and movies.\n",
            "****\n",
            "entry: 44\n",
            "q: What is the purpose of Robert A. Gonsalves' project GANfolk?\n",
            "a: The purpose of GANfolk, a project by Robert A. Gonsalves, is to use AI to create portraits of fictional people. He noticed that Generative Adversarial Networks (GANs) often struggle with creating images of people, so he decided to tackle this challenge by training two GANs using paintings and photographs of people. The images created were then put up for sale as NFTs in a collection on OpenSea. He also released the dataset of training images, the source code, and the trained models under the Creative Commons Attribution Share-alike license, allowing others to use his code to create their own digital paintings of people and sell them, provided they give him attribution.\n",
            "****\n",
            "entry: 45\n",
            "q: What are the three \"directions\" for changing face image in InterFaceGAN as mentioned by Robert A. Gonsalves in \"Portraits from the Multiverse\"?\n",
            "a: In \"Portraits from the Multiverse\", he mentioned that the three \"directions\" for changing face image in InterFaceGAN are age, smile, and pose.\n",
            "****\n",
            "entry: 46\n",
            "q: What is one limitation of the DALL-E model as mentioned by Robert A. Gonsalves in his article 'E-DALL-E: Creating Digital Art with Varying Aspect Ratios'?\n",
            "a: According to him, one limitation of the DALL-E model is that the output it produces is relatively small, at 256x256 pixels.\n",
            "****\n",
            "entry: 47\n",
            "q: What are some of the limitations of GPT-4 as mentioned by Robert A. Gonsalves in his article 'Writing Songs with GPT-4: Part 2, Chords'?\n",
            "a: According to Robert, GPT-4, despite its advanced capabilities, has limitations similar to its predecessors. It is not fully reliable and can suffer from \"hallucinations\". It also has a limited context window and does not learn. Furthermore, the outputs of GPT-4 can sometimes reflect societal biases and worldviews that may not align with the user's intent or widely shared values. He advises caution when using the outputs of GPT-4, especially in contexts where reliability is important.\n",
            "****\n",
            "entry: 48\n",
            "q: What creative uses of AI does Robert A. Gonsalves often write about?\n",
            "a: He often writes about generating digital art, using AI for writing prose, and composing music.\n",
            "****\n",
            "entry: 49\n",
            "q: How does VoxMorphia classify the generated text in terms of safety?\n",
            "a: VoxMorphia uses GPT-3's classification system to flag the generated text as safe, sensitive, or unsafe. Safe text is considered harmless, while sensitive text could be discussing political, religious, or other sensitive topics. Unsafe text contains profane language, prejudiced or hateful language, or could be considered not safe for work. In Robert's examples, lyrics in the style of Bob Marley and Radiohead were occasionally flagged as sensitive, while those in the style of Megan Thee Stallion were consistently flagged as unsafe.\n",
            "****\n",
            "entry: 50\n",
            "q: What are the two key concepts that Robert A. Gonsalves explains in his article \"Benford’s Law — A Simple Explanation\"?\n",
            "a: In his article, he explains the concepts of normal distributions and logarithms.\n",
            "****\n",
            "entry: 51\n",
            "q: What are the main components used in the MAGnet project?\n",
            "a: The main components used in the MAGnet project include CLIP, SWAGAN, and a custom genetic algorithm. The process also involves gathering, filtering, and training a GAN with images from WikiArt, similar to the process used in his previous project, GANscapes.\n",
            "****\n",
            "entry: 52\n",
            "q: What are some of the societal implications Robert A. Gonsalves discusses in relation to the use of ML systems like StyleCLIP?\n",
            "a: In \"Portraits from the Multiverse\", he discusses how these ML systems can sometimes show signs of cultural biases. For example, the system might render certain ethnicities with stereotypical features, which could be due to a lack of diverse representation in the dataset. He also mentions the societal impacts of biases and uneven representation in datasets used for ML, such as the potential for cultural export of racial systems from privileged, wealthy, industrialized countries that are the primary producers of datasets. This could lead to these exported racial systems taking on a validity outside of their cultural context, with potentially dangerous consequences. He emphasizes the importance of understanding and trying to offset these cultural biases in ML systems.\n",
            "****\n",
            "entry: 53\n",
            "q: What was Robert A. Gonsalves' main purpose in exploring DALL-E for digital art creation?\n",
            "a: His main purpose was to test OpenAI’s text-to-image generator, DALL-E, to see how it would perform in creating images using a variety of subjects and styles.\n",
            "****\n",
            "entry: 54\n",
            "q: What is the purpose of the GreenLit project by Robert A. Gonsalves?\n",
            "a: The purpose of the GreenLit project by Robert A. Gonsalves is to fine-tune a machine learning model, specifically GPT-J, to create new screenplays for TV shows and movies. This includes generating new titles, plot summaries, and scripts.\n",
            "****\n",
            "entry: 55\n",
            "q: How did Robert A. Gonsalves utilize the Universal Sentence Encoder in his project, Organic Topic Modelling?\n",
            "a: In his project, Organic Topic Modelling, Robert used the Universal Sentence Encoder from Google to convert each topic phrase into an embedding, which is an array of 512 floating-point numbers. This essentially represents the concept of the topic phrase in the encoder's multidimensional space. For instance, he demonstrated this with the phrase \"love loss\". Although the resulting numbers may not be interpretable to humans, he used statistical methods to make sense of these topics.\n",
            "****\n",
            "entry: 56\n",
            "q: How does E-DALL-E maintain the central part of the image relatively constant while expanding the image?\n",
            "a: E-DALL-E maintains the central part of the image relatively constant by replacing the center part of the modified image vectors with the center of the vectors from the input image after each iteration. This ensures that only the sides of the image undergo significant changes.\n",
            "****\n",
            "entry: 57\n",
            "q: What are the main functions of DALL-E for creating images as described by Robert A. Gonsalves?\n",
            "a: According to him, DALL-E has three main functions for creating images. These functions can work with either generated or uploaded images.\n",
            "****\n",
            "entry: 58\n",
            "q: What improvements did Robert A. Gonsalves notice in GPT-4 compared to GPT-3 in terms of writing lyrics?\n",
            "a: He noticed a substantial increase in the quality of responses from GPT-4 compared to GPT-3, particularly in its ability to generate rhyming words.\n",
            "****\n",
            "entry: 59\n",
            "q: How did Robert extract keywords for each limerick in the AI Limericks project?\n",
            "a: In the AI Limericks project, he used a tool called KeyBert to extract the keywords for each limerick. He incorporated these keywords into the training data to enable the model to generate new limericks based on user-supplied topics.\n",
            "****\n",
            "entry: 60\n",
            "q: How does the GANscapes project use the CLIP model from OpenAI?\n",
            "a: The GANscapes project uses the CLIP model from OpenAI in two ways. First, it uses CLIP to filter the initial set of Impressionist landscape paintings, keeping only the \"good ones.\" Later, it uses CLIP again to filter the output images based on a user-supplied text query. This ensures that the final images generated align with the user's desired style and form.\n",
            "****\n",
            "entry: 61\n",
            "q: What is the issue with the faces generated using the MetFaces dataset and StyleGAN 2 ADA according to Robert A. Gonsalves?\n",
            "a: According to him, the faces generated using the MetFaces dataset and StyleGAN 2 ADA are too tightly cropped. Additionally, he notes a distinct lack of cultural diversity in the generated faces.\n",
            "****\n",
            "entry: 62\n",
            "q: What is the purpose of the InventorBot project by Robert A. Gonsalves?\n",
            "a: The purpose of the InventorBot project by Robert is to use artificial intelligence to generate new ideas in any field. The AI is trained on the US Patent Database and can produce new and possibly useful inventions.\n",
            "****\n",
            "entry: 63\n",
            "q: What is the licensing model for the source code of the Clip-n-Paste project by Robert A. Gonsalves?\n",
            "a: The source code for the Clip-n-Paste project is released under the CC BY-SA license.\n",
            "****\n",
            "entry: 64\n",
            "q: How does Robert A. Gonsalves create a background color gradient for the photo collages in the Clip-n-Paste project?\n",
            "a: In the Clip-n-Paste project, he creates a background color gradient for the photo collages by writing a Python code that creates a vertical color gradient with five control points. He then uses CLIP to analyze the resultant image and iteratively adjusts the colors using the Adam optimizer in Pytorch to find the best match for the text prompt. This process involves tweaking the parameters a little and observing if and how much the results improve for each iteration. The parameters are changed at different rates depending on how much each parameter contributes to improving the results.\n",
            "****\n",
            "entry: 65\n",
            "q: What techniques did Robert A. Gonsalves use to generate improved abstract paintings with AI in the project 'StyleGAN Abstract Art'?\n",
            "a: In the 'StyleGAN Abstract Art' project, he used Adaptive Discriminator Augmentation and Learning Transfer to generate improved abstract paintings with AI.\n",
            "****\n",
            "entry: 66\n",
            "q: What was Robert A. Gonsalves' solution to the slow processing time of the AI he was training to rhyme?\n",
            "a: To address the slow processing time of the AI, Robert upgraded to Pro on Colab. This allowed for faster training of the AI, although it did come at a cost, as each limerick ended up costing him a dime.\n",
            "****\n",
            "entry: 67\n",
            "q: What is the name of the neural network that Stephen Thaler created and trained to invent things?\n",
            "a: The neural network that Stephen Thaler created and trained to invent things is named DABUS, which stands for \"Device Autonomously Bootstrapping Uniform Sensibility\", as mentioned in \"InventorBot: Using AI to Generate New Ideas in Any Field\" by Robert A. Gonsalves.\n",
            "****\n",
            "entry: 68\n",
            "q: What are the differences between selling NFTs on the Ethereum and Polygon blockchains according to Robert A. Gonsalves in his article \"GANshare: Creating and Curating Art with AI for Fun and Profit\"?\n",
            "a: According to Robert, there are several differences between selling NFTs on the Ethereum and Polygon blockchains. For instance, initializing an account on the Ethereum blockchain costs around US$50, while it's free on the Polygon blockchain. Both blockchains have a selling cost of 2.5%. However, selling items in bundles is only possible on the Ethereum blockchain. In terms of blockchain validation, Ethereum uses proof of work while Polygon uses proof of stake. Lastly, the environmental impact of Ethereum is huge, although this is expected to change in Q1/Q2 2022, while Polygon's environmental impact is minimal.\n",
            "****\n",
            "entry: 69\n",
            "q: What is the main purpose of the GANfolk project as described by Robert A. Gonsalves?\n",
            "a: The main purpose of the GANfolk project, as described by Robert A. Gonsalves, is to use artificial intelligence, specifically StyleGAN2, VQGAN, and GPT-3, to create portraits of fictional characters from open-source images. These AI-generated portraits are then sold as NFTs (Non-Fungible Tokens).\n",
            "****\n",
            "entry: 70\n",
            "q: What platform did Robert A. Gonsalves use to train the MachineRay GAN and how long did it take?\n",
            "a: He used Google Colab Pro to train the MachineRay GAN. It took him about 13 days to train the GAN, during which he sent 5 million source images through the system.\n",
            "****\n",
            "entry: 71\n",
            "q: What are the three methods of searching that Robert A. Gonsalves describes in his article \"Using OpenAI’s CLIP to Search for Design Patents\"?\n",
            "a: In his article, he describes three methods for searching design patents. The first is a text to text search, which compares the embedding of the query to the list of text embeddings for the design patent captions. The second is a text to image search, which compares the query embedding to the list of image embeddings. The third method is a text to combined text/image search, which replicates the query embedding and compares the combined pair to a list of combined text and image embeddings.\n",
            "****\n",
            "entry: 72\n",
            "q: What is the main topic that Robert A. Gonsalves discusses in his article 'Benford’s Law — A Simple Explanation'?\n",
            "a: In his article, Robert A. Gonsalves provides a simple explanation of Benford's Law, also known as the \"First-Digit Law\".\n",
            "****\n",
            "entry: 73\n",
            "q: What are some of the improvements Robert A. Gonsalves suggests for the MAGnet project?\n",
            "a: Robert suggests that the MAGnet system could be improved by training with more images to reduce the frequency of repeated visual themes. He also mentions that the textures within the images could be enhanced as there seem to be some \"computery\" artifacts in the flat areas, possibly due to the reimplementation of the CUDA operations.\n",
            "****\n",
            "entry: 74\n",
            "q: What is the main focus of Robert A. Gonsalves' article \"Using ChatGPT as a Creative Writing Partner — Part 1: Prose\"?\n",
            "a: The main focus of his article is to explore how the latest language model from OpenAI, known as ChatGPT, can be utilized as a tool for creative writing, specifically in the genres of poetry, fiction, and screenplays.\n",
            "****\n",
            "entry: 75\n",
            "q: What were the results of Robert's test on the three upsizing options in Midjourney V4?\n",
            "a: Robert found that all three upsizing options - lite, regular, and beta - in Midjourney V4 showed fine details in the final images. However, he noted that the beta upsize seemed a bit more orderly, with elements like the inner ring on the dialer appearing more realistically formed.\n",
            "****\n",
            "entry: 76\n",
            "q: What is the focus of Robert A. Gonsalves' article \"Using ChatGPT as a Creative Writing Partner — Part 3: Picture Books\"?\n",
            "a: In his article, Robert A. Gonsalves discusses how the latest language model from OpenAI, known as ChatGPT, can be used as a tool for writing children's books and creating illustrations with Midjourney.\n",
            "****\n",
            "entry: 77\n",
            "q: What is the rule of thumb for using BIG.art as suggested by Robert A. Gonsalves?\n",
            "a: According to him, a good rule of thumb for using BIG.art is to do a Google search of the prompt and look at the resulting images. If they look roughly similar, then generating an image using that prompt will likely produce good results. However, he advises against trying to render people, as it won't work due to the intentional lack of people in the training data for GLIDE.\n",
            "****\n",
            "entry: 78\n",
            "q: How does Robert retrieve the random seed used to generate images in Midjourney Art?\n",
            "a: In Midjourney Art, Robert retrieves the random seed used to generate images by first creating an image. After the image is generated, he creates a \"reaction\" to his image and chooses the \"envelope\" emoji. This action triggers the bot to send him a message that includes the seed for the run. He then uses the --seed parameter to generate the same image with different options.\n",
            "****\n",
            "entry: 79\n",
            "q: What is the main focus of Robert A. Gonsalves' article \"Writing Songs with GPT-4: Part 3, Melodies\"?\n",
            "a: The main focus of his article is on how to use the latest language model from OpenAI, GPT-4, to assist in writing melodies for new songs.\n",
            "****\n",
            "entry: 80\n",
            "q: What is the main purpose of the GANfolk system as described by Robert A. Gonsalves?\n",
            "a: The main purpose of the GANfolk system, as described by him, is to use artificial intelligence to create portraits of fictional people. These AI-generated portraits are then sold as NFTs (Non-Fungible Tokens). The system utilizes StyleGAN2, VQGAN, and GPT-3 to synthesize diverse characters from open-source images.\n",
            "****\n",
            "entry: 81\n",
            "q: What metric did Robert A. Gonsalves use to measure the quality and diversity of the images produced by StyleGAN2 ADA?\n",
            "a: He used the Fréchet Inception Distance (FID) as a metric to measure the quality and diversity of the images produced by StyleGAN2 ADA. A lower FID score indicates better image quality and diversity.\n",
            "****\n",
            "entry: 82\n",
            "q: What is the new version of Nvidia's AI model that Robert A. Gonsalves used in his project to create better looking abstract paintings?\n",
            "a: He used the new version of Nvidia's AI model called StyleGAN2 ADA (SG2A) in his project to generate improved abstract artwork.\n",
            "****\n",
            "entry: 83\n",
            "q: What does Robert A. Gonsalves say about the improvements in toxicity and bias in the new model compared to GPT-3?\n",
            "a: According to him, the new model shows only minor improvements in toxicity over GPT-3, but no improvement in bias.\n",
            "****\n",
            "entry: 84\n",
            "q: What is the main topic that Robert A. Gonsalves discusses in his article 'Benford’s Law — A Simple Explanation'?\n",
            "a: In his article, Robert A. Gonsalves provides a simple explanation of Benford's Law, a mathematical phenomenon also known as the \"First-Digit Law\". He discusses its history, its applications, and some of the theories that have been proposed to explain why it holds true in many real-world data sets.\n",
            "****\n",
            "entry: 85\n",
            "q: What was Robert A. Gonsalves' latest experiment in the article \"Using ChatGPT as a Creative Writing Partner — Part 3: Picture Books\"?\n",
            "a: In this article, his latest experiment involved creating a picture book using ChatGPT. He asked the system to describe scenes, which he then rendered using Midjourney, a text-to-image creation system.\n",
            "****\n",
            "entry: 86\n",
            "q: What are the strengths of the two GANs, StyleGAN2 and VQGAN, that Robert used in the GANfolk project?\n",
            "a: In the GANfolk project, Robert found that StyleGAN2 excelled at creating a global structure in the generated images that closely resembled the types in the training data, but it often produced hazy or missing image details. On the other hand, VQGAN was proficient at filling in realistic image details, but it struggled to create a global structure. Therefore, he used both GANs to leverage their strengths and compensate for their weaknesses.\n",
            "****\n",
            "entry: 87\n",
            "q: What is the main purpose of Robert A. Gonsalves' project, PlotJam?\n",
            "a: The main purpose of PlotJam, as explained by Robert, is to use AI and Machine Learning to help writers overcome writer's block. He uses an ML model called GPT-2 to generate new plot summaries, providing a starting point for writers to create new stories.\n",
            "****\n",
            "entry: 88\n",
            "q: What was Robert A. Gonsalves' main objective in the Muybridge Derby project?\n",
            "a: His main objective was to use Midjourney and RunwayML to transform Eadweard Muybridge’s photo sequences into high-resolution videos.\n",
            "****\n",
            "entry: 89\n",
            "q: What is the main focus of Robert A. Gonsalves' article \"Using ChatGPT as a Creative Writing Partner — Part 2: Music\"?\n",
            "a: In his article, he explores how the latest language model from OpenAI, ChatGPT, can be utilized to compose chords for new songs. He also discusses the use of music by Band-in-a-Box in this process.\n",
            "****\n",
            "entry: 90\n",
            "q: How does the AI 8-Ball extract keywords from a user's question?\n",
            "a: The AI 8-Ball uses an algorithm called TextRank to extract keywords and phrases from the user's question. This algorithm is based on the PageRank algorithm used for web searches. It takes a block of text and returns key phrases ranked by relevance. For example, from the question \"Can a computer beat a grandmaster chess player?\", it extracts the key phrases \"a grandmaster\", \"chess player\", and \"a computer\".\n",
            "****\n",
            "entry: 91\n",
            "q: What significant difference did Robert A. Gonsalves notice between the fourth and previous versions of Midjourney Art?\n",
            "a: Robert noticed that the fourth version of Midjourney Art creates initial renderings at a resolution of 512x512, unlike the previous versions which created images at 256x256. Additionally, he observed a significant improvement in the quality of images generated by the fourth version compared to its predecessors.\n",
            "****\n",
            "entry: 92\n",
            "q: What machine learning tools does Robert A. Gonsalves suggest using to create high-resolution digital paintings?\n",
            "a: Robert A. Gonsalves suggests using GLIDE and BSRGAN to create ultra-high-resolution digital paintings with fine details.\n",
            "****\n",
            "entry: 93\n",
            "q: How did Robert use GPT-4 to create song lyrics in the style of the ska band, The Agents?\n",
            "a: Robert started by having GPT-4 analyze the lyrics and chords of the song “Grow” by The Agents. He then gave GPT-4 a new theme about overcoming fears and asked it to create five possible song titles with descriptions. After selecting the title \"Dance with the Fear\", he asked GPT-4 to write the lyrics for the new song. When he noticed a couplet that didn't rhyme, he asked GPT-4 to rewrite it, which it did successfully. This process demonstrated how Robert used GPT-4 as a writing partner in creating song lyrics.\n",
            "****\n",
            "entry: 94\n",
            "q: How did Robert A. Gonsalves train the Deep Haiku model?\n",
            "a: Robert started by downloading two datasets of Haikus from Kaggle.com. He then used FastPunct to add punctuation and casing to the Haikus and ran the KeyBERT model to extract phrases used as prompts. He filtered the data using the GRUEN metric and the phoenemizer library to count the syllables and convert the prompts and Haikus into phonemes. This resulted in over 26K high-quality Haikus with a [5, 7, 5] meter. He then used the GPT-J 6B model from Eluther as the basis for Deep Haiku and fine-tuned it using the filtered Haikus as training data for ten epochs. This process took 11 hours on Google Colab with a Tesla V100 GPU.\n",
            "****\n",
            "entry: 95\n",
            "q: What was Robert A. Gonsalves' critique of current AI models for generating music?\n",
            "a: Robert A. Gonsalves noted that while AI models have shown proficiency in generating images and text, their performance in composing music has been less impressive. He pointed out that the output from most music generating AI models, including Google's Magenta, OpenAI's MuseNet, and AIVA, often lacks coherence and structure. He suggested that this issue could potentially be addressed by incorporating lyrical poetry into the process.\n",
            "****\n",
            "entry: 96\n",
            "q: What is the next model that the developers behind GPT-Neo at EleutherAI are planning to build?\n",
            "a: The developers at EleutherAI are planning to build and train a new model called GPT-NeoX. Their primary goal with this model is to train an equivalent to the full-sized GPT-3 and make it available to the public under an open license.\n",
            "****\n",
            "entry: 97\n",
            "q: How does Robert A. Gonsalves use GPT-3 Da Vinci to generate funny captions for memes?\n",
            "a: Robert A. Gonsalves uses GPT-3 Da Vinci by creating a prompt that describes the image for which he wants to generate a caption. He then passes this prompt into a call to OpenAI along with additional parameters that control the length and variety of the response. After running the code, he gets a list of potential captions. He found that GPT-3 Da Vinci can indeed generate humorous captions, such as one that cleverly refers to the idiom \"easy as pie\".\n",
            "****\n",
            "entry: 98\n",
            "q: What are the three real datasets that Robert A. Gonsalves used to demonstrate the adherence to Benford's Law?\n",
            "a: Robert A. Gonsalves used the datasets of city/town populations, accounts payable, and lengths of rivers to demonstrate how datasets with a lognormal distribution will tend to adhere to Benford's Law.\n",
            "****\n",
            "entry: 99\n",
            "q: What techniques did Robert A. Gonsalves use to transform Muybridge’s animal locomotion photographs into high-resolution, full-color videos?\n",
            "a: He used a combination of Midjourney to create reference frames from text prompts and RunwayML’s Gen-1 Video Generator to transform the original sequences into more realistic ones. He also generated a background scroll and combined the elements to create an animation called \"Muybridge Derby\".\n",
            "****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_qa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7892
        },
        "id": "TiBxNbGK0oH9",
        "outputId": "9ce397bb-a2a1-42df-925d-76839ec5a0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         doc_metadata  \\\n",
              "0   {'title': 'Writing Songs with GPT-4: Part 2, C...   \n",
              "1   {'title': '#Hands-on Tutorials', 'subtitle': '...   \n",
              "2   {'title': 'Using AI to Create New Comic Strips...   \n",
              "3   {'title': 'Using AI to Create New Comic Strips...   \n",
              "4   {'title': 'BIG.art: Using Machine Learning to ...   \n",
              "..                                                ...   \n",
              "95  {'title': 'Frost Songs: Using AI to Generate M...   \n",
              "96  {'title': 'AI-Memer: Using Machine Learning to...   \n",
              "97  {'title': 'AI-Memer: Using Machine Learning to...   \n",
              "98  {'title': 'Benford’s Law — A Simple Explanatio...   \n",
              "99  {'title': 'Muybridge Derby: Bringing Animal Lo...   \n",
              "\n",
              "                                          doc_content  \\\n",
              "0   Source Code\\nThe source code for this project ...   \n",
              "1   Using CLIP to Filter the Images for Training\\n...   \n",
              "2   Final Thoughts\\nComparing the two systems, I f...   \n",
              "3   Mark Madness\\nFor the Mark Madness comic, I us...   \n",
              "4   Source Code\\nThe  source code  for this projec...   \n",
              "..                                                ...   \n",
              "95  Background\\nFor the last five months, I have b...   \n",
              "96  Next Steps\\nAlthough the results are pretty go...   \n",
              "97  GPT-3 Da Vinci\\nOpenAI’s GPT-3 Da Vinci is cur...   \n",
              "98  Summary\\nIn this article, I gave an overview o...   \n",
              "99  Muybridge Derby\\nFor this project, I wanted to...   \n",
              "\n",
              "                                             question  \\\n",
              "0   What is the main objective of Robert A. Gonsal...   \n",
              "1   How did Robert use CLIP to filter the images f...   \n",
              "2   What are the limitations Robert A. Gonsalves f...   \n",
              "3   How did Robert A. Gonsalves modify the images ...   \n",
              "4   What machine learning tools does Robert A. Gon...   \n",
              "..                                                ...   \n",
              "95  What was Robert A. Gonsalves' critique of curr...   \n",
              "96  What is the next model that the developers beh...   \n",
              "97  How does Robert A. Gonsalves use GPT-3 Da Vinc...   \n",
              "98  What are the three real datasets that Robert A...   \n",
              "99  What techniques did Robert A. Gonsalves use to...   \n",
              "\n",
              "                                               answer  \n",
              "0   The main objective of his project 'GPT-4 Chord...  \n",
              "1   Robert used CLIP to filter the images by compa...  \n",
              "2   Robert found that while DALL-E could generate ...  \n",
              "3   Robert cleaned up the images in Photoshop, add...  \n",
              "4   He uses GLIDE and BSRGAN to create these high-...  \n",
              "..                                                ...  \n",
              "95  Robert A. Gonsalves noted that while AI models...  \n",
              "96  The developers at EleutherAI are planning to b...  \n",
              "97  Robert A. Gonsalves uses GPT-3 Da Vinci by cre...  \n",
              "98  Robert A. Gonsalves used the datasets of city/...  \n",
              "99  He used a combination of Midjourney to create ...  \n",
              "\n",
              "[100 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c99fb653-e6fd-4931-89f7-17c1312b2466\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_metadata</th>\n",
              "      <th>doc_content</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'title': 'Writing Songs with GPT-4: Part 2, C...</td>\n",
              "      <td>Source Code\\nThe source code for this project ...</td>\n",
              "      <td>What is the main objective of Robert A. Gonsal...</td>\n",
              "      <td>The main objective of his project 'GPT-4 Chord...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'title': '#Hands-on Tutorials', 'subtitle': '...</td>\n",
              "      <td>Using CLIP to Filter the Images for Training\\n...</td>\n",
              "      <td>How did Robert use CLIP to filter the images f...</td>\n",
              "      <td>Robert used CLIP to filter the images by compa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'title': 'Using AI to Create New Comic Strips...</td>\n",
              "      <td>Final Thoughts\\nComparing the two systems, I f...</td>\n",
              "      <td>What are the limitations Robert A. Gonsalves f...</td>\n",
              "      <td>Robert found that while DALL-E could generate ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'title': 'Using AI to Create New Comic Strips...</td>\n",
              "      <td>Mark Madness\\nFor the Mark Madness comic, I us...</td>\n",
              "      <td>How did Robert A. Gonsalves modify the images ...</td>\n",
              "      <td>Robert cleaned up the images in Photoshop, add...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'title': 'BIG.art: Using Machine Learning to ...</td>\n",
              "      <td>Source Code\\nThe  source code  for this projec...</td>\n",
              "      <td>What machine learning tools does Robert A. Gon...</td>\n",
              "      <td>He uses GLIDE and BSRGAN to create these high-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>{'title': 'Frost Songs: Using AI to Generate M...</td>\n",
              "      <td>Background\\nFor the last five months, I have b...</td>\n",
              "      <td>What was Robert A. Gonsalves' critique of curr...</td>\n",
              "      <td>Robert A. Gonsalves noted that while AI models...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>{'title': 'AI-Memer: Using Machine Learning to...</td>\n",
              "      <td>Next Steps\\nAlthough the results are pretty go...</td>\n",
              "      <td>What is the next model that the developers beh...</td>\n",
              "      <td>The developers at EleutherAI are planning to b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>{'title': 'AI-Memer: Using Machine Learning to...</td>\n",
              "      <td>GPT-3 Da Vinci\\nOpenAI’s GPT-3 Da Vinci is cur...</td>\n",
              "      <td>How does Robert A. Gonsalves use GPT-3 Da Vinc...</td>\n",
              "      <td>Robert A. Gonsalves uses GPT-3 Da Vinci by cre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>{'title': 'Benford’s Law — A Simple Explanatio...</td>\n",
              "      <td>Summary\\nIn this article, I gave an overview o...</td>\n",
              "      <td>What are the three real datasets that Robert A...</td>\n",
              "      <td>Robert A. Gonsalves used the datasets of city/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>{'title': 'Muybridge Derby: Bringing Animal Lo...</td>\n",
              "      <td>Muybridge Derby\\nFor this project, I wanted to...</td>\n",
              "      <td>What techniques did Robert A. Gonsalves use to...</td>\n",
              "      <td>He used a combination of Midjourney to create ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c99fb653-e6fd-4931-89f7-17c1312b2466')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c99fb653-e6fd-4931-89f7-17c1312b2466 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c99fb653-e6fd-4931-89f7-17c1312b2466');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-82b48be6-bf83-40d4-8053-a3ca36df0601\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82b48be6-bf83-40d4-8053-a3ca36df0601')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-82b48be6-bf83-40d4-8053-a3ca36df0601 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5290da47-87f4-4461-ac18-45966cf8bb42\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_qa')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5290da47-87f4-4461-ac18-45966cf8bb42 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_qa');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_qa.to_csv('robgon_qa.csv', index=False)\n",
        "df_qa.to_csv('robgon_qa.csv', index=False, encoding='utf-8-sig')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KElT0ca22igV",
        "outputId": "b5fda8b9-984d-4ff5-fa81-c5b61af2e866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}